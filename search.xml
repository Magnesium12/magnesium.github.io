<?xml version="1.0" encoding="utf-8"?>
<search>
  <entry>
    <title><![CDATA[The Next]]></title>
    <url>%2F2018%2F12%2F16%2FThe%20NexT%2F</url>
    <content type="text"><![CDATA[谨以此文, 纪念一个误入NexT坑的年轻人 Next主题个性化 Tips:hexo s后可以直接本地调试，也就是更改文件保存后，Hexo 后台会自动重新渲染文件，所以只要稍等片刻，浏览器刷新一下就能看到效果。 无序列表圆点不喜欢默认空心圆无序列表，我们换成实心的列表： 主题目录： source/css/_common/components/post/post-expand.styl:1ul li &#123; list-style: disc; &#125; 页面列表：next/source/css/_custom/custom.styl:123ul &#123; list-style-type: disc; // 空心圆，实心圆为 disc&#125; 参考：https://github.com/iissnan/hexo-theme-next/issues/559 主页文章阴影打开\themes/next/source/css/_custom/下的custom.styl, 添加12345678// 主页文章添加阴影效果.post &#123; margin-top: 0px; margin-bottom: 60px; padding: 25px; -webkit-box-shadow: 0 0 5px rgba(202, 203, 203, .5); -moz-box-shadow: 0 0 5px rgba(202, 203, 204, .5);&#125; 添加顶部加载条打开主题配置文件1234567891011121314151617181920# Progress bar in the top during page loading.# Dependencies: https://github.com/theme-next/theme-next-pacepace: false #点击上述链接, 下载pace. 然后把这个修改为true# Themes list:#pace-theme-big-counter#pace-theme-bounce#pace-theme-barber-shop#pace-theme-center-atom#pace-theme-center-circle#pace-theme-center-radar#pace-theme-center-simple#pace-theme-corner-indicator#pace-theme-fill-left#pace-theme-flash#pace-theme-loading-bar#pace-theme-mac-osx#pace-theme-minimal# For example# pace_theme: pace-theme-center-simplepace_theme: pace-theme-minimal 修改网页底部图标还是打开themes/next/layout/_partials/footer.swig，找到：1234&lt;span itemprop="copyrightYear"&gt;&#123;&#123; current &#125;&#125;&lt;/span&gt; &lt;span class="with-love" id="animate"&gt; &lt;i class="fas fa-igloo"&gt;&lt;/i&gt; &lt;/span&gt; 前往FontAwesome获取相应图标并替换 1&lt;i class="fas fa-igloo"&gt;&lt;/i&gt; 文章加密访问打开themes-&gt;next-&gt;layout-&gt;\_partials-&gt;head-&gt;head.swig文件,在以下位置插入这样一段代码： 1234567891011121314&lt;script&gt; (function () &#123; if ('&#123;&#123; page.password &#125;&#125;') &#123; if (prompt('请输入文章密码') !== '&#123;&#123; page.password &#125;&#125;') &#123; alert('密码错误！'); if (history.length === 1) &#123; location.replace("http://zlee.xyz"); // 这里替换成你的首页 &#125; else &#123; history.back(); &#125; &#125; &#125; &#125;)();&lt;/script&gt; 萌え萌えlive2d首先安装live2d模块1npm install --save hexo-helper-live2d 然后选择要安装的live2d模型1npm install live2d-widget-model-[填入代号] 在站点/主题配置文件_config.yml中追加1234567891011121314151617181920212223242526272829# Live2D## https://github.com/xiazeyu/live2d-widget.js## https://l2dwidget.js.org/docs/class/src/index.js~L2Dwidget.html#instance-method-initlive2d: enable: true scriptFrom: local pluginRootPath: live2dw/ pluginJsPath: lib/ pluginModelPath: assets/ tagMode: false debug: false model: use: live2d-widget-model-koharu scale: 1 hHeadPos: 0.5 vHeadPos: 0.618 display: superSample: 1 width: 150 height: 300 position: left hOffset: 20 vOffset: 0 mobile: show: true scale: 0.5 react: opacityDefault: 0.7 opacityOnHover: 0.2 大小方向自行调参, 重新生成即可. 如果生成出现YAML 解析错误, 请检查是否正确采用tab缩进. 设置代码块这是一个很长的故事…….]]></content>
      <categories>
        <category>Hexo</category>
      </categories>
      <tags>
        <tag>施工中</tag>
        <tag>一时兴起</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[数据结构]]></title>
    <url>%2F2018%2F12%2F13%2F%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84%2F</url>
    <content type="text"><![CDATA[谨以此文, 纪念我没怎么听过的数据结构 线性表线性表是数据元素的非空有限集合 唯一一个“ 开始节点” 唯一一个” 终端节点“ 除开始结点外，集合中的每个数据元素均只有一个直接前驱 除终端结点外，集合中的每个数据元素均只有一个直接后继 顺序表线性表的结点按逻辑次序存放在一组地址连续的存储单元里, 例如数组 loc(ai)=loc(a1)+(i-1)*c 代码实现分析插入算法和删除算法都是O(n) ### 排序 对由n个记录组成的表(或文件)L=(r1,r2,…….,rn)，依据记录中某个数据项的值重新进行排列的过程称之为排序（sorting），该数据项称为排序码，一般情况下， 总是选择记录的关键码(字)作为排序码。 如果待排序的表中含有多个排序码值相等的记录，用某种排序方法排序后，这些记录的相对次序不变，则说这种排序方法为稳定的（stable），否则是不稳定的。 归并排序归并排序（merge sort）是归并操作上的一种有效的排序算法归并排序每次都是在相邻的数据中进行操作，在O(N*logN)的几种排序方法（快速排序，归并排序，希尔排序，堆排序）也是效率比较高的。 设数列长为N，将数列分开成小数列一共要logN步，每步都是一个合并有序数列的过程，时间复杂度可以记为O(N)，故一共为O(N*logN)。 算法思路对于整体无序的数列 递归(recursion)分割数列为左右两部分, 直至数列不可再分 对当前不可再分的左右数列进行归并 代码实现12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364#include&lt;iostream&gt;using namespace std;//归并排序void merge(int arr[], int front, int mid, int rear, int temp[]) &#123; int i = front, j = mid + 1, k = 0; while (i &lt;= mid &amp;&amp; j &lt;= rear) &#123; if (arr[i] &lt; arr[j]) &#123; temp[k++] = arr[j++]; &#125; else &#123; temp[k++] = arr[i++]; &#125; &#125; while (i &lt;= mid) &#123; temp[k++] = arr[i++]; &#125; while (j &lt;= rear) &#123; temp[k++] = arr[j++]; &#125; for (int i = 0; i &lt; k; i++) &#123; arr[front + i] = temp[i]; &#125;&#125;void recursive(int arr[],int front, int rear, int temp[]) &#123; if (front&lt;rear) &#123; int mid = (front + rear) / 2; recursive(arr, front, mid, temp); recursive(arr, mid + 1, rear, temp); merge(arr, front, mid, rear, temp); &#125;&#125;bool mergeSort(int arr[], int n) &#123; //辅助表空间, 避免数列数组被覆写, 省去临时声明空间的时间开销 int* temp = new int [n]; if (temp == NULL) &#123; return false; &#125; recursive(arr, 0, n - 1, temp); delete[] temp; return true;&#125;int main() &#123; int arr[8] = &#123; 12,12,123,45,654,78,96,2 &#125;; mergeSort(arr, 8); for (size_t i = 0; i &lt; 8; i++) &#123; cout &lt;&lt; arr[i] &lt;&lt; "\t"; &#125; system("pause");&#125; 堆排序堆排序是利用堆这种数据结构而设计的一种排序算法，它是一种选择排序，它的最坏，最好，平均时间复杂度均为O(nlogn)，它也是不稳定排序。 算法思路 将无需序列构建成一个堆，根据升序降序需求选择大顶堆或小顶堆; 将堆顶元素与末尾元素交换，将最大元素”沉”到数组末端; 重新调整结构，使其满足堆定义，然后继续交换堆顶元素与当前末尾元素，反复执行调整+交换步骤，直到整个序列有序。 代码实现1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859#include&lt;iostream&gt;using namespace std;void swap(int arr[], int front, int rear) &#123; int tmp = arr[front]; arr[front] = arr[rear]; arr[rear] = tmp;&#125;void adjustHeap(int arr[], int i, int len) &#123; int temp = arr[i]; for (int k = i * 2 + 1; k &lt; len; k = k * 2 + 1) &#123; if ((k + 1) &lt; len&amp;&amp;arr[k] &lt; arr[k + 1]) &#123; k++; &#125; if (arr[k] &gt; temp) &#123; arr[i] = arr[k]; i = k; &#125; else &#123; break; &#125; &#125; arr[i] = temp;&#125;void sort(int arr[], int len) &#123; //1. 构建大顶堆 for (int i = len / 2 - 1; i &gt;= 0; i--) &#123; adjustHeap(arr, i, len); &#125; //2. 交换堆顶元素和末尾元素, 调整堆 for (int i = len - 1; i &gt; 0; i--) &#123; swap(arr, 0, i); adjustHeap(arr, 0, i); &#125;&#125;int main() &#123; int arr[8] = &#123; 1,2,45,65,78,98,45,32 &#125;; sort(arr, 8); for (int i = 0; i &lt; 8; i++) &#123; cout &lt;&lt; arr[i] &lt;&lt; "\t"; &#125; system("pause");&#125; 基数排序基数排序 (radix sort) 属于”分配式排序” (distribution sort) , 重点在于对关键字进行 “分配” 和 “收集” , 而不是对关键字的比较.基数排序算法是稳定的, 时间复杂度是O(d*(n＋r)) 将表中n个记录分配到r个队列中去的时间为O(n), 收集时将r个队列连成一个表的时间O(r), 一次分配和收集的时间为O(n＋r), 由于算法对n个记录共进行了d遍分配和收集,所以共花费的时间为O(d*(n＋r)). 算法思路 将关键码按照位数最小/最大值分配入箱 按照箱子的顺序收集关键码 重复1，2步骤直到位数到达最大/最小值 代码实现最高位优先(Most Significant Digit first)，简称MSD最低位优先(Least Significant Digit first)，简称LSD下面采用LSD法，值得一提的是，这种实现比较耗费内存, 从理论上来说, 申请的数组空间利用率只有10%.123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475#include&lt;iostream&gt;/*顺序数组实现*/using namespace std;const int RADIX = 10;//桶数const int Max = 10;//桶容量int getDigit(int src, int pos) &#123; int temp = 1; for (int i = 0; i &lt; pos - 1; ++i) &#123; temp *= 10; &#125; return (src / temp) % 10;&#125;void radixSort_Array(int *src, int digits) &#123; int* tempArray[RADIX];//定义桶数 RADIX for (int i = 0; i &lt; RADIX; ++i)//定义桶容量 &#123; tempArray[i] = new int [Max + 1]; tempArray[i][0] = 0;//初始化为0 &#125; for (int pos = 1; pos &lt;= digits; ++pos) &#123; int tmp; for (int i = 0; i &lt; Max; ++i)//分配进桶 &#123; tmp = getDigit(src[i], pos);//获取指定位的数字 ++tempArray[tmp][0]; tempArray[tmp][tempArray[tmp][0]] = src[i]; &#125; int index = 0; for (int i = 0;i&lt;RADIX; ++i)//收集 &#123; for (int j = 1; j &lt;=tempArray[i][0]; ++j ) &#123; src[index++] = tempArray[i][j]; &#125; tempArray[i][0] = 0;//重置 &#125; cout &lt;&lt; endl; for (int i = 0; i &lt; Max; i++) &#123; cout &lt;&lt; src[i] &lt;&lt; "\t"; &#125; &#125;&#125;int main() &#123; int src[Max] = &#123; 12,123,123,14,56,78,56,12,456,789 &#125;; /*std::cout &lt;&lt; "最大三位数" &lt;&lt; std::endl; for (RADIX_t i = 0; i &lt; Max; i++) &#123; std::cin &gt;&gt; src[i]; cout &lt;&lt; endl; &#125;*/ for (int i = 0; i &lt; Max; i++) &#123; cout &lt;&lt; src[i] &lt;&lt; "\t"; &#125; radixSort_Array(src, 3); cout &lt;&lt; endl; for (int i = 0; i &lt; Max; i++) &#123; cout &lt;&lt; src[i]&lt;&lt;"\t"; &#125; system("pause");&#125; `]]></content>
      <categories>
        <category>课程</category>
      </categories>
      <tags>
        <tag>课程笔记</tag>
        <tag>自学OTZ</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Tutorial For Hexo]]></title>
    <url>%2F2018%2F12%2F12%2FSimple-Tutorial-For-Hexo%2F</url>
    <content type="text"><![CDATA[Hexo是一款基于Node.js的静态博客框架，可以方便的生成静态网页托管在GitHub和Heroku上，是搭建博客的首选框架。Hexo同时也是GitHub上的开源项目，如果想要更加全面的了解Hexo，可以到其官网 Hexo 了解更多的细节，因为Hexo的创建者是台湾人，对中文的支持很友好，你可以查阅到优质的中文文档. Hexo基础基于Github pages 的静态博客所必须的步骤 GitHubGitHub提供了一个免费账户, 这对于我们来说可以很方便的搭建静态博客, 当然, 这也是本篇的目标. 登录到GitHub, 如果没有GitHub帐号，使用你的邮箱注册GitHub帐号. 点击GitHub中的New repository创建新仓库，仓库名应该为： 1用户名.github.io 用户名请使用你的GitHub帐号名称代替. 这是固定写法，比如我的仓库名为:1magnesium12.github.io 安装Git&amp;Node.js在安装前，你必须检查电脑中是否已安装下列应用程序： Node.js Git Windows 用户 如果你的电脑中尚未安装所需要的程序，请到官网下载Node.js &amp; Git的安装程序进行安装.注意安装Node.js时注意勾选Add to PATH选项, 这将使得Node.js添加到你的计算机环境变量中.Git安装完成后，右键菜单会出现git bash, 我们所有的命令都需要在git bash中执行,. 下载Git可能会有些慢, 请耐心等待或者自行寻找过其他源. 配置SSH免密访问 本地安装 Git 我本地是Windows，采用 git-bash. 如果你是新手的话, 在安装过程中只要一路next就OK 配置本地免密ssh远程登陆 在本地写作的机器上，搜索Git Bash，设置user.name和user.email配置信息：12git config --global user.name "你的GitHub用户名"git config --global user.email "你的GitHub注册邮箱" 生成ssh密钥文件 1ssh-keygen -t rsa -C "你的GitHub注册邮箱" 一路回车，~/.ssh/目录下会生成 id_rsa 和 id_rsa.pub 两个文件。 打开GitHub_Settings_keys 页面，新建new SSH Key Title为标题，任意填即可，将刚刚复制的id_rsa.pub内容粘贴进去，最后点击Add SSH key.在Git Bash中检测GitHub公钥设置是否成功，输入1​ssh git@github.com 如果是第一次链接的话, 可能会询问是否创建 known_hosts文件, 当然是yes 建站如果你的电脑中已经安装上述必备程序，那么恭喜你！接下来只需使用 npm 即可完成 Hexo 的安装。 1$ npm install -g hexo-cli Hexo安装完成后, 输入以下命令并执行 123$ hexo init &lt;folder&gt;$ cd &lt;folder&gt;$ npm install 请注意, &lt;folder&gt;是你指定的文件夹路径, 并且该文件夹必须为空. &lt;`&gt;`是特殊字符, 命令端输入时应当去除, 例如 123hexo init /d/Project/Hexocd /d/Project/Hexonpm install 或者直接打开Hexo文件夹, 右键git bash, 输入1hexo init 如果你看到1INFO Start blogging with Hexo!` 这意味着本地建站已完成, congratulations!你已经到达新手村. 站点结构新建完成后, 本地hexo站点结构如下 12345678.├── _config.yml├── package.json├── scaffolds├── source| ├── _drafts| └── _posts└── themes _config.yml网站的配置信息, 你可以在这里选择配置大部分参数, 我们称为站点配置文件. 可以设定主题, 网站标题, 副标题, author etc. 详情请阅读.md文档 package.json应用程序的信息. scaffolds模板文件夹, Hexo会根据scaffolds来建立文件. Hexo的模板是指在新建的markdown文件中默认填充的内容. 例如, 如果您修改scaffold/post.md中的Front-matter内容, 那么每次新建一篇文章时都会包含这个修改. source资源文件夹是存放用户资源的地方. 除_posts 文件夹之外, 开头命名为 _ (下划线)的文件 / 文件夹和隐藏的文件将会被忽略. Markdown 和 HTML 文件会被解析并放到 public 文件夹, 而其他文件会被拷贝过去. 发布的博文存储在/public/ theme主题 文件夹。Hexo 会根据主题来生成静态页面。 存在默认主题, 但还是请选择一个你喜欢的主题, it does matter. 主题文件夹内会有_config.yml配置文件, 我们称为主题配置文件 Hexo常用指令**请注意, 这些操作必须在../hexo/目录下进行 init$ hexo init [folder] 新建一个网站。如果没有设置 folder , Hexo 默认在目前的文件夹建立网站. new$ hexo new [layout] &lt;title&gt; $ hexo n &quot;article&quot; 新建一篇文章。如果没有设置 layout 的话，默认使用 _config.yml 中的 default_layout 参数代替。如果标题包含空格的话，请使用引号括起来。 generate$ hexo generate $ hexo g 生成静态文件。 deploy$ hexo deploy $ hexo d 文件生成后立即部署网站 generate$ hexo gengerate $ hexo g server$ hexo server $ hexo s 启动服务器。默认情况下，访问网址为： http://localhost:4000/ . 如果需要修改,​ $ hexo sever -p 5000 #更改端口至5000 clean$ hexo clean 清除缓存文件 (db.json) 和已生成的静态文件 (public)。在某些情况（尤其是更换主题后）, 如果发现您对站点的更改无论如何也不生效, 您可能需要运行该命令. 发布网站如果你已经迫不及待地打开在hexo 目录下打开Git bash12hexo ghexo s 在http://localhost:4000 你将预览到自己的博客, 但是别人是看不到的, 毕竟一般情况下别人不能看到你的计算机的本地内容. Github pages可以帮助我们解决这个问题. 下一步把GitHub和我们的Hexo关联起来, 打开站点的_config.yml, 找到1234deploy: type: repo: branch: 修改如下:12345deploy: type: git #创建仓库的完整路径, 末尾记得加.git repo: https://github.com/Magnesium12/magnesium12.github.io.git branch: master 其实就是给hexo d 这个命令做相应的配置，让hexo知道你要把blog部署在哪个位置，很显然，我们部署在我们GitHub的仓库里。最后安装Git部署插件, 输入命令: npm install hexo-deployer-git --save 现在我们输入:123hexo cleanhexo ghexo d 在浏览器中输入: xxxx. github.io 你会发现这时你的博客已经上线, Congratulations! Now. Sharing the fantasy of your own to the world. Hexo进阶安装注意到6.x版本next仓库的变动, 需要下载最新版本的同学请选择 12cd hexogit clone https://github.com/theme-next/hexo-theme-next themes/next 之后跟进更新12cd theme/nextgit pull 如果是从v5.x升级到v6.x, 请另行参阅这篇文档 主题配置 打开_config.yml 文件 阅读 README.md 依照字面意思来配置 常见问题眼睛不需要的话, 可以捐给其他人. by 鲁迅 .swig1Unhandled rejection Error: ENOENT: no such file or directory, open 'D:\Project\Hexo\themes\next\layout\_scripts\schemes\.swig' NexT使用版本: 5.1.4原因：social加入链接时, #social: 这一行没有把注释打开….. 怎么写博客 请bing一下markdown. 此外, 推荐VS Code作为你的博客项目管理工具. 推荐Typora作为你写markdown的书写工具. 语言设定请修改站点文件, zh-CN意味着站点语言默认为中文1language: zh-CN 标签&amp;分类进入hexo文件夹1hexo new page "tags" 注意已生成source/tags/index.md, index.md中修改如下12345---title: categoriesdate: 2016-11-15 19:11:13type: "tags"--- 当你试图为你的文章添加标签时, 请在文章头部添加12345---title: 基于Hexo和Github搭建博客date: 2018-12-14tags: [npm, hexo, github]--- categories 分类 如上]]></content>
      <categories>
        <category>Hexo</category>
      </categories>
      <tags>
        <tag>施工中</tag>
        <tag>021</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Python爬虫（三）：从JSON解决Ajax]]></title>
    <url>%2F2018%2F12%2F07%2FPython%E7%88%AC%E8%99%AB%EF%BC%88%E4%B8%89%EF%BC%89%EF%BC%9A%E7%88%AC%E5%8F%96js%E5%8A%A8%E6%80%81%E7%BD%91%E9%A1%B5%2F</url>
    <content type="text"><![CDATA[上一篇博文中, 笔者采用了selenium驱动chrome来抓取网页, 总结来看及其低效….. 想了一下, 不能这样搞, 他要刷新局部界面肯定是要利用JavaScript调用已经写好的json的. 通常来说不会有前端选择瞎搞地址. 如果能观察出那个json的地址特点, 就到了ButifulSoup为所欲为的时间辣(●’◡’●) 对于json参数偏移量不规律的网页,那当然是 直接打死 ,哦不, 仔细观察. 对于一个正常的前端同学来说, 不规律的json只可能是有限的, 我不做人啦,jojo!. 我们只要把有限的偏移量写成一个字典(dic)就大功告成 前期准备 Chrome浏览器 Python3.7 requests, BeautifulSoup4模块 一点点耐心以及正常的视力 流程分析 chrome浏览器打开目标网页, 检查元素 F12, CTRL+ shift+i, CTRL+shift+c爱用那个用哪个 继续加载内容，注意观察network栏下的xhr文件 很明显，那个since=就是我们要找的*点击展开，根据 Query string 构造parameter参数字典 requests 负责请求，bs4 为所欲为 代码实现12345678910111213141516171819202122json_url = 'https://富强民主文明和谐'#无规则偏移量，自行逆向分析得到偏移量字典since_list = [26961.554, 26961.474, 26961.419, 26961.346]#实现提取json，加载动态内容，但是封装性不好，不能重复利用def getMorePages(list,count=1): params_list = [] for i in range(count): keyword=str(list[i]) params_list.append(&#123; 'since': keyword, 'grid_type': 'flow', 'sort': 'hot', 'tag_id': '399', &#125;) url = json_url for i in params_list: req=requests.get(url, params=i).content soup=BeautifulSoup(req,'lxml') getURL(soup) 尾声很显然，这样做效率会高很多 发现json规律成为了木桶的最短板，为了避免那个网站被薅羊毛，我就手动屏蔽惹OTZ……另外，代码只放入了相关的一部分，有兴趣的同学可以尝试结合上一篇，整合功能鸭~Good night！]]></content>
      <categories>
        <category>Python</category>
      </categories>
      <tags>
        <tag>Web Crawler</tag>
        <tag>实例</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[推歌：A LETTER]]></title>
    <url>%2F2018%2F12%2F03%2F%E6%AD%8C%E6%9B%B2%E6%8E%A8%E8%8D%90The-Song-For-You%2F</url>
    <content type="text"><![CDATA[You don’t have to throw your life away 本来也不想写文字，但是不写一点文字,又怎么知道当时所思所想是什么，自己又是为什么要去写这篇博文呢? …… A LETTER 是由泽野弘之创作的插曲——也许提及高达UC会让他更容易被想起. 歌姬Cyua确实很适合去唱这首歌, 她的声线与舒缓空旷的乐音彼此交融, 编织出这首弥漫着伤感, 空灵以及希望的歌曲. 倘若你愿意闭上双眸, 浮现出的场景大概会是独角兽在孤独地进行着只属于自己的宇宙漫途, 但或许你需要知道的是, 这首歌曲更多在表达的是对自己的鼓励和对未来的希冀. 每个人都是宇宙中的独角兽, 命运指定的航线终将我们彼此分离, 忙碌追赶又有什么意义呢？命运的轨迹充满了错误, 等待我们的会是痛苦, 遗憾, 还是……希望? 指向正确的道路或许很艰辛, 可是总有一天能够到达尽头. Now you see light in pain. Kevin .]]></content>
      <categories>
        <category>随笔</category>
      </categories>
      <tags>
        <tag>私货</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Python爬虫（二）：Selenium + ChromeDriver 解决异步加载]]></title>
    <url>%2F2018%2F12%2F01%2FPython%E7%88%AC%E8%99%AB%EF%BC%88%E4%BA%8C%EF%BC%89%EF%BC%9ASelenium%20%2B%20ChromeDriver%20%E8%A7%A3%E5%86%B3%E5%BC%82%E6%AD%A5%E5%8A%A0%E8%BD%BD%2F</url>
    <content type="text"><![CDATA[在上一篇博文中, python代码趋向于平铺直叙——或者说代码习惯十分不好, 稍微复杂点的功能都会举步维艰 对于选择使用js控制加载网页结构的网站, 以urllib为基础的python库来说无法直接解决这个问题，例如爬取下拉刷新的网页：”https://bcy.net/coser&quot; 但是事在人为, 对于笔者这个小白来说还是有傻瓜式替代解决思路的, 虽然很慢== 前期准备 默认看过Python爬虫（一）：Requests&amp;BS4 爬虫实例 预装模块: requests, selenium, bs4, os 下载chromedriver 流程分析 bs4+selenium+chromedriver 强行爆破 模拟点击行为获取完全加载的html 然后用beautifulsoup为所欲为代码实现 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118# coding=utf-8# **************************Declaration**************************# @File name: Crawler# @Function: requests+selenium+chromedriver# @Author: Ogiso Kazusa# @Date: 2018/11/15# @Version Number: 2.0# ******************************end******************************import requestsimport osfrom bs4 import BeautifulSoupfrom selenium import webdriver#常量URL = 'https://bcy.net'index_url = 'https://bcy.net/coser'CachePath = "D:\\CrawlerCache\\"#储存CN的键值对, 用于isInDic()dic=&#123;'test':0&#125;#检查字典, 判断是否下载过def isInDic(src): if src in dic: dic[src] = dic[src] + 1 else: dic[src] = 0 dst = src + "_" + str(dic[src]) return dstdef mkdir(path): # 去除首位空格 path = path.strip() # 去除尾部 \ 符号 path = path.rstrip("\\") # 判断路径是否存在 # 存在 True # 不存在 False isExists = os.path.exists(path) # 判断结果 if not isExists: # 如果不存在则创建目录 # 创建目录操作函数 os.makedirs(path) print(path + ' 创建成功') return True else: # 如果目录存在则不创建，并提示目录已存在 print(path + ' 目录已存在') return False# 实现图片下载功能def downloadImg(url, name): # 请求url页面内容,此时页面为图床页面,只有图片内容 url = requests.get(url) # 格式和下载位置 path = CachePath + name + ".jpg" # 迭代器和生成器,实现下载 with open(path, 'wb') as f: f.write(url.content) f.close()#驱动chrome,获取加载完全的html#木桶效应的最短板, 也是本次解决方案的致命点def getJsHtml(URL, cosImg): driver = webdriver.Chrome() driver.get(URL) html = driver.page_source driver.close() soup = BeautifulSoup(html, 'lxml') content = soup.find_all('div', &#123;"class": "img-wrap-inner"&#125;) i = 1 for element in content: src = element.find('img')['src'] name=cosImg + '_' + str(i) downloadImg(src, name) print("下载进度：",i) i = i + 1# 确定存储目录CachePath,没有则生成mkdir(CachePath)# 请求页面内容session = requests.get(index_url) # 获取requests 对象的内容，建议使用content，requests会尝试提供字节数soup = BeautifulSoup(session.content, "lxml") # find 直接返回值, findall 返回列表(list)index = soup.find_all('a', &#123;'class': "db posr ovf"&#125;)for element in index: # print(element)可以看到 # 利用标签的父子关系，能够选择标签或者子标签中的属性值 # 我们获取cos发布地址 img_url = element['href'] url = URL + img_url # CN = element.get('title')貌似两种写法均可 CN = element['title'] print('准备下载：' + CN) CN = isInDic(CN) getJsHtml(url, CN)#大功告成#可以考虑指定需要获取的json？ 尾声 吐槽一下, 这玩意儿奇慢无比, 调用浏览器中出现了大量不必要的步骤== 另一种意义上的模拟人类点击机制, 慢也有点用?,效率实在太低 令人头皮发麻，]]></content>
      <categories>
        <category>Python</category>
      </categories>
      <tags>
        <tag>Web Crawler</tag>
        <tag>实例</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Python爬虫（一）:Requests&BS4 爬虫实例]]></title>
    <url>%2F2018%2F12%2F01%2FPython%E7%88%AC%E8%99%AB%EF%BC%88%E4%B8%80%EF%BC%89%EF%BC%9ARequests%26BS4%20%E7%88%AC%E8%99%AB%E5%AE%9E%E4%BE%8B%2F</url>
    <content type="text"><![CDATA[这篇文章主要是方便入门爬虫的同学获得入门的正反馈，配合代码注释可能轻松愉悦的对爬虫有个大概了解~ 我们选择对于使用静态网页的小说网站, 小说的文本内容往往分配在一个&lt;div里, 逻辑比较简单. 那就开始吧＜（＾－＾）＞ 前期准备 安装python3.7 安装requests, BeautifulSoup4(或者说bs4) 安装chrome浏览器 掌握Python基础语法 可以尝试 菜鸟教程-Python 3 教程 流程分析 请求URL指向的页面-&gt;获取网页内容 设定筛选条件-&gt;获取指定内容 写入本地文件 检查网站代码 ctrl +shift +c, 检查网页源代码[^3], 得知章节地址F12, ctrl+shift+i , 右键-检查, 等等均可 [^3]:本教程仅供参考, 保护创作者版权, 提倡付费阅读 根据章节地址跳转页面 检查章节页面, 得知章节文本内容 代码实现1234567891011121314151617181920212223242526272829303132333435363738394041424344454647# coding=utf-8# *********************Declaration*********************# @File name: WebCrawler# @Function: Download Single Novel# @Author: Ogiso Kazusa # @Date: 2018/11/14 # @Version Number: 1.0 # *************************end*************************#导入模块import requestsfrom bs4 import BeautifulSoup#小说网页目录地址, 准备遍历全部章节地址index_url='https://www.88dush.com/xiaoshuo/27/27584/'#获取页面内容index_req=requests.get(index_url)index_html=index_req.contentpage_main=BeautifulSoup(index_html,"lxml")#创建D盘根目录文件“单本下载.txt”，#格式为ab+:向二进制文件末添加数据，且允许读；fo=open("D:\\单本下载.txt","ab+")#获取div , class="mulu" 包含的内容chap_BS=page_main.find("div",&#123;"class":"mulu"&#125;)#生成器对象for child in chap_BS.ul.children: if child!="\n": #href：目标url的属性名 chap_url=index_url+child.a.get("href") #素质三联，获取lxml文档 chap_req=requests.get(chap_url) chap_html=chap_req.content.decode("gbk") soup_text=BeautifulSoup(chap_html,"lxml") #寻找div段落，class=yd_text2的属性块内容 chap_text=soup_text.find("div"，&#123;"class":"yd_text2"&#125;) #.text指获取文字内容，\r\n是指写入文件中的换行符, == fo.write((child.string+ "\r\n"+chap_text.text+"\r\n").encode('utf-8')) print(child.string+'\t已下载') fo.close() 最后Enjoy it !]]></content>
      <categories>
        <category>Python</category>
      </categories>
      <tags>
        <tag>Web Crawler</tag>
        <tag>实例</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[A Whisper To The World]]></title>
    <url>%2F2018%2F12%2F01%2FA-Whisper-To-The-World%2F</url>
    <content type="text"><![CDATA[NieR:Automata Everything that lives is designed to end.一切活着的事物，都注定要终结。We are perpetually trapped …我们被永远地囚禁……… in a never-ending spiral of life and death.……于永无止境的生死轮回之中。Is this a curse?这是一种诅咒？Or some kind of punishment?还是某种惩罚？I often think about the god who blessed us with this cryptic puzzle …我时常想起那用模糊的谜团祝福我们的神……… and wonder if we’ll ever have the chance to kill him.……并猜想我们是否终有弑神的机会。]]></content>
      <categories>
        <category>随笔</category>
      </categories>
      <tags>
        <tag>Ridiculous</tag>
        <tag>Thought</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Hello World]]></title>
    <url>%2F2018%2F11%2F30%2Fhello-world%2F</url>
    <content type="text"><![CDATA[Welcome to Hexo! This is your very first post. Check documentation for more info. If you get any problems when using Hexo, you can find the answer in troubleshooting or you can ask me on GitHub. Quick StartCreate a new post1$ hexo new "My New Post" More info: Writing Run server1$ hexo server More info: Server Generate static files1$ hexo generate More info: Generating Deploy to remote sites1$ hexo deploy More info: Deployment]]></content>
      <tags>
        <tag>hello</tag>
      </tags>
  </entry>
</search>
